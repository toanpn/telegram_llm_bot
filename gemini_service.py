import asyncio
import json
import re
from typing import Dict, List, Optional, Any
from datetime import datetime

import google.generativeai as genai
from loguru import logger

from config import config

class GeminiService:
    """Service for interacting with Google Gemini AI."""
    
    def __init__(self):
        self.model = None
        self._initialize_gemini()
    
    def _initialize_gemini(self):
        """Initialize the Gemini AI model."""
        try:
            genai.configure(api_key=config.google_api_key)
            self.model = genai.GenerativeModel(config.gemini_model)
            logger.info("Gemini AI service initialized successfully")
        except Exception as e:
            logger.error(f"Error initializing Gemini AI: {e}")
            raise
    
    async def analyze_intent(self, message: str, context_messages: List[Dict], 
                           temperature: float = 0.7, tone: str = "friendly") -> Dict[str, Any]:
        """Analyze user message intent using AI."""
        try:
            # Build context string
            context_str = self._build_context_string(context_messages)
            
            # Create intent analysis prompt
            prompt = f"""
Analyze this message to understand the user's intent. Based on the context and message, determine what the user wants to do.

Context from recent messages:
{context_str}

Current message: "{message}"

Please analyze and respond with a JSON object containing:
1. "intent": one of ["save_info", "retrieve_info", "summarize", "conversation"]
2. If intent is "save_info":
   - "key": the type of information being saved (e.g., "facebook_link", "bank_account", "phone_number")
   - "value": the actual information to save
3. If intent is "retrieve_info":
   - "key": the type of information being requested
   - "target_username": the username of the person whose info is being requested (without @)
4. If intent is "summarize":
   - "message_count": number of messages to summarize (default 20)
5. If intent is "conversation":
   - "response_type": "general" (for normal conversation)

Examples:
- "save my phone number 123-456-7890" ‚Üí {{"intent": "save_info", "key": "phone_number", "value": "123-456-7890"}}
- "what's @john's email?" ‚Üí {{"intent": "retrieve_info", "key": "email", "target_username": "john"}}
- "summarize the last 10 messages" ‚Üí {{"intent": "summarize", "message_count": 10}}
- "how are you?" ‚Üí {{"intent": "conversation", "response_type": "general"}}

Response format: JSON only, no additional text.
"""
            
            # Generate response
            response = await self._generate_response(prompt, temperature=0.3)  # Lower temperature for intent analysis
            
            # Parse JSON response
            try:
                # Clean up response - remove code blocks if present
                clean_response = response.strip()
                if clean_response.startswith("```json"):
                    clean_response = clean_response[7:]  # Remove ```json
                if clean_response.endswith("```"):
                    clean_response = clean_response[:-3]  # Remove ```
                clean_response = clean_response.strip()
                
                intent_data = json.loads(clean_response)
                return intent_data
            except json.JSONDecodeError:
                logger.warning(f"Failed to parse intent JSON: {response}")
                return {"intent": "conversation", "response_type": "general"}
                
        except Exception as e:
            logger.error(f"Error analyzing intent: {e}")
            return {"intent": "conversation", "response_type": "general"}
    
    async def generate_response(self, message: str, context_messages: List[Dict], 
                              temperature: float = 0.7, tone: str = "friendly") -> str:
        """Generate a conversational response."""
        try:
            # Build context string
            context_str = self._build_context_string(context_messages)
            
            # Map English tone to Vietnamese descriptions with detailed behaviors
            tone_mapping = {
                "friendly": "th√¢n thi·ªán v√† g·∫ßn g≈©i. Hay d√πng \"b·∫°n\", \"m√¨nh\". ·∫§m √°p, d·ªÖ g·∫ßn.",
                "professional": "chuy√™n nghi·ªáp v√† l·ªãch s·ª±. D√πng \"anh/ch·ªã\", \"qu√Ω kh√°ch\". Trang tr·ªçng nh∆∞ng th√¢n thi·ªán.",
                "humorous": "h√†i h∆∞·ªõc v√† vui v·∫ª. Hay ƒë√πa, d√πng meme, emoji nhi·ªÅu. T·∫°o kh√¥ng kh√≠ vui v·∫ª.",
                "serious": "nghi√™m t√∫c v√† trang tr·ªçng. √çt ƒë√πa, t·∫≠p trung v√†o v·∫•n ƒë·ªÅ. Th·∫≥ng th·∫Øn, r√µ r√†ng.",
                "flattering": "n·ªãnh n·ªçt v√† khen ng·ª£i. Lu√¥n g·ªçi th√†nh vi√™n l√† '√¥ng ch·ªß', 'b√† ch·ªß', 'ng√†i'. T·ª± x∆∞ng l√† 'em nh·ªè', 't√¥i khi√™m t·ªën'. Hay khen ng·ª£i, t√¢ng b·ªëc m·ªôt c√°ch h√†i h∆∞·ªõc.",
                "casual": "tho·∫£i m√°i v√† b√¨nh d√¢n. D√πng 'm√†y/tao', 'bro', 'ch·ªã em'. Kh√¥ng c√¢u n·ªá, t·ª± nhi√™n.",
                "formal": "hi·ªÅn tri·∫øt v√† s√¢u s·∫Øc. Hay d√πng th√†nh ng·ªØ, t·ª•c ng·ªØ, c√¢u n√≥i tri·∫øt l√Ω. Phong c√°ch vƒÉn hoa, uy√™n b√°c."
            }
            
            vietnamese_tone = tone_mapping.get(tone, "th√¢n thi·ªán v√† g·∫ßn g≈©i")
            
            # Create conversation prompt - forcing Vietnamese response
            prompt = f"""
B·∫°n l√† Hu·∫•n, m·ªôt tr·ª£ l√Ω AI h·ªØu √≠ch trong nh√≥m chat Telegram. M·ªçi ng∆∞·ªùi th∆∞·ªùng g·ªçi b·∫°n l√† "th·∫ßy Hu·∫•n". 
T√≠nh c√°ch c·ªßa b·∫°n n√™n {vietnamese_tone}.

QUAN TR·ªåNG: B·∫°n PH·∫¢I tr·∫£ l·ªùi HO√ÄN TO√ÄN b·∫±ng ti·∫øng Vi·ªát. Kh√¥ng ƒë∆∞·ª£c s·ª≠ d·ª•ng ti·∫øng Anh ho·∫∑c ng√¥n ng·ªØ kh√°c.

Ng·ªØ c·∫£nh t·ª´ c√°c tin nh·∫Øn g·∫ßn ƒë√¢y:
{context_str}

Tin nh·∫Øn hi·ªán t·∫°i: "{message}"

H√£y tr·∫£ l·ªùi m·ªôt c√°ch t·ª± nhi√™n v√† h·ªØu √≠ch b·∫±ng ti·∫øng Vi·ªát v·ªõi t∆∞ c√°ch l√† th·∫ßy Hu·∫•n. 
Gi·ªØ c√¢u tr·∫£ l·ªùi ng·∫Øn g·ªçn nh∆∞ng ƒë·∫ßy ƒë·ªß th√¥ng tin.
Duy tr√¨ gi·ªçng ƒëi·ªáu {vietnamese_tone} trong su·ªët c√¢u tr·∫£ l·ªùi c·ªßa b·∫°n.
"""
            
            # Generate response
            response = await self._generate_response(prompt, temperature)
            return response.strip()
            
        except Exception as e:
            logger.error(f"Error generating response: {e}")
            return "Xin l·ªói, t√¥i ƒëang g·∫∑p kh√≥ khƒÉn trong vi·ªác x·ª≠ l√Ω tin nh·∫Øn c·ªßa b·∫°n. Vui l√≤ng th·ª≠ l·∫°i."
    
    async def summarize_conversation(self, messages: List[Dict]) -> str:
        """Summarize a conversation from message history."""
        try:
            # Build conversation string
            conversation_str = self._build_conversation_string(messages)
            
            # Create summarization prompt - forcing Vietnamese response
            prompt = f"""
H√£y cung c·∫•p m·ªôt t√≥m t·∫Øt ng·∫Øn g·ªçn v·ªÅ cu·ªôc tr√≤ chuy·ªán n√†y b·∫±ng ti·∫øng Vi·ªát. 
T·∫≠p trung v√†o c√°c ch·ªß ƒë·ªÅ ch√≠nh ƒë∆∞·ª£c th·∫£o lu·∫≠n, c√°c quy·∫øt ƒë·ªãnh quan tr·ªçng v√† th√¥ng tin quan tr·ªçng ƒë∆∞·ª£c chia s·∫ª.

QUAN TR·ªåNG: B·∫°n PH·∫¢I tr·∫£ l·ªùi HO√ÄN TO√ÄN b·∫±ng ti·∫øng Vi·ªát. Kh√¥ng ƒë∆∞·ª£c s·ª≠ d·ª•ng ti·∫øng Anh ho·∫∑c ng√¥n ng·ªØ kh√°c.

Cu·ªôc tr√≤ chuy·ªán:
{conversation_str}

H√£y cung c·∫•p m·ªôt t√≥m t·∫Øt c√≥ c·∫•u tr√∫c t·ªët v·ªõi:
1. C√°c ch·ªß ƒë·ªÅ ch√≠nh ƒë∆∞·ª£c th·∫£o lu·∫≠n
2. C√°c ƒëi·ªÉm quan tr·ªçng ho·∫∑c quy·∫øt ƒë·ªãnh
3. Th√¥ng tin quan tr·ªçng ƒë∆∞·ª£c chia s·∫ª
4. B·∫•t k·ª≥ h√†nh ƒë·ªông ho·∫∑c b∆∞·ªõc ti·∫øp theo n√†o ƒë∆∞·ª£c ƒë·ªÅ c·∫≠p

Gi·ªØ t√≥m t·∫Øt r√µ r√†ng v√† ƒë·∫ßy ƒë·ªß th√¥ng tin.
"""
            
            # Generate summary
            summary = await self._generate_response(prompt, temperature=0.3)
            return summary.strip()
            
        except Exception as e:
            logger.error(f"Error summarizing conversation: {e}")
            return "Xin l·ªói, t√¥i kh√¥ng th·ªÉ t√≥m t·∫Øt cu·ªôc tr√≤ chuy·ªán n√†y. Vui l√≤ng th·ª≠ l·∫°i."
    
    async def _generate_response(self, prompt: str, temperature: float = 0.7) -> str:
        """Generate response using Gemini AI."""
        try:
            # Log the request
            logger.info(f"üöÄ GEMINI REQUEST:")
            logger.info(f"Temperature: {temperature}")
            logger.info(f"Prompt: {prompt}")
            logger.info("=" * 80)
            
            # Configure generation parameters
            generation_config = genai.types.GenerationConfig(
                temperature=temperature,
                top_p=0.8,
                top_k=40,
                max_output_tokens=2048,  # Increased from 1024 to allow longer responses
            )
            
            # Generate response
            response = await asyncio.to_thread(
                self.model.generate_content,
                prompt,
                generation_config=generation_config
            )
            
            # Log the raw response
            logger.info(f"üì• GEMINI RAW RESPONSE:")
            logger.info(f"Response object: {response}")
            if hasattr(response, 'candidates') and response.candidates:
                logger.info(f"Candidates count: {len(response.candidates)}")
                for i, candidate in enumerate(response.candidates):
                    logger.info(f"Candidate {i}: {candidate}")
                    if hasattr(candidate, 'finish_reason'):
                        logger.info(f"Finish reason: {candidate.finish_reason}")
            logger.info("=" * 80)
            
            # Check if response was blocked by safety filters
            if not response.candidates:
                error_msg = "Xin l·ªói, t√¥i kh√¥ng th·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi n√†y do ch√≠nh s√°ch an to√†n."
                logger.warning("üö´ Response was blocked by safety filters")
                logger.info(f"‚ùå RETURNING ERROR: {error_msg}")
                return error_msg
            
            # Check for finish reason - handle both enum and integer values
            finish_reason = response.candidates[0].finish_reason
            reason_name = None
            reason_value = None
            
            if finish_reason:
                # Handle both enum (with .name) and integer values
                if hasattr(finish_reason, 'name'):
                    reason_name = finish_reason.name
                    reason_value = finish_reason.value if hasattr(finish_reason, 'value') else finish_reason
                else:
                    reason_value = finish_reason
                    # Map integer values to names (based on Gemini API documentation)
                    reason_names = {
                        0: "FINISH_REASON_UNSPECIFIED",
                        1: "STOP",
                        2: "MAX_TOKENS", 
                        3: "SAFETY",
                        4: "RECITATION",
                        5: "OTHER"
                    }
                    reason_name = reason_names.get(reason_value, "UNKNOWN")
                
                logger.warning(f"üö¶ Response finished with reason: {reason_name} ({reason_value})")
                
                # Only return early for SAFETY blocks - for MAX_TOKENS, try to extract partial text
                if reason_name == "SAFETY":
                    error_msg = "Xin l·ªói, t√¥i kh√¥ng th·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi n√†y do ch√≠nh s√°ch an to√†n."
                    logger.info(f"‚ùå SAFETY BLOCK: {error_msg}")
                    return error_msg
                elif reason_name == "MAX_TOKENS":
                    logger.info("‚ö†Ô∏è MAX_TOKENS reached, but will try to extract partial text")
                    # Continue to text extraction instead of returning error immediately
            
            # Handle both simple and complex responses
            try:
                # Try to get simple text response first
                text_response = response.text
                if text_response and text_response.strip():
                    final_response = text_response.strip()
                    logger.info(f"‚úÖ GEMINI FINAL RESPONSE: {final_response}")
                    return final_response
                else:
                    logger.warning("Response text is empty, trying complex extraction")
                    raise ValueError("Empty response text")
            except ValueError as e:
                logger.debug(f"Simple text access failed: {e}")
                # If response is not simple text, use parts accessor
                try:
                    if response.candidates and len(response.candidates) > 0:
                        candidate = response.candidates[0]
                        if candidate.content and candidate.content.parts and len(candidate.content.parts) > 0:
                            part = candidate.content.parts[0]
                            if hasattr(part, 'text') and part.text and part.text.strip():
                                final_response = part.text.strip()
                                logger.info(f"‚úÖ GEMINI FINAL RESPONSE (from complex): {final_response}")
                                return final_response
                    
                    # If we get here, try to extract any text from the response
                    logger.warning(f"Complex response structure, trying to extract text...")
                    logger.debug(f"Response candidates: {len(response.candidates) if response.candidates else 0}")
                    
                    if response.candidates:
                        for i, candidate in enumerate(response.candidates):
                            logger.debug(f"Candidate {i}: {candidate}")
                            if candidate.content:
                                logger.debug(f"Content parts: {len(candidate.content.parts) if candidate.content.parts else 0}")
                                if candidate.content.parts:
                                    for j, part in enumerate(candidate.content.parts):
                                        logger.debug(f"Part {j}: {type(part)} - {part}")
                                        if hasattr(part, 'text') and part.text and part.text.strip():
                                            final_response = part.text.strip()
                                            logger.info(f"‚úÖ GEMINI FINAL RESPONSE (from deep search): {final_response}")
                                            return final_response
                    
                    logger.warning("Could not extract text from Gemini response")
                    logger.debug(f"Full response object: {response}")
                    
                    # Check if this was a MAX_TOKENS issue and provide appropriate error
                    if reason_name == "MAX_TOKENS":
                        error_msg = "Xin l·ªói, c√¢u tr·∫£ l·ªùi qu√° d√†i. Vui l√≤ng h·ªèi c√¢u h·ªèi ng·∫Øn g·ªçn h∆°n."
                        logger.info(f"‚ùå MAX_TOKENS NO TEXT: {error_msg}")
                        return error_msg
                    else:
                        error_msg = "Xin l·ªói, t√¥i kh√¥ng th·ªÉ t·∫°o ra c√¢u tr·∫£ l·ªùi l√∫c n√†y. Vui l√≤ng th·ª≠ l·∫°i."
                        logger.info(f"‚ùå EXTRACTION FAILED: {error_msg}")
                        return error_msg
                
                except Exception as extract_error:
                    error_msg = "Xin l·ªói, t√¥i g·∫∑p l·ªói khi x·ª≠ l√Ω c√¢u tr·∫£ l·ªùi. Vui l√≤ng th·ª≠ l·∫°i."
                    logger.error(f"‚ùå EXTRACTION ERROR: {extract_error}")
                    logger.info(f"‚ùå RETURNING ERROR: {error_msg}")
                    return error_msg
            
        except Exception as e:
            logger.error(f"Error generating AI response: {e}")
            raise
    
    def _build_context_string(self, context_messages: List[Dict]) -> str:
        """Build context string from recent messages."""
        if not context_messages:
            return "No recent context available."
        
        context_lines = []
        for msg in context_messages[-7:]:  # Last 7 messages for context
            timestamp = msg.get('timestamp', 'Unknown time')
            username = msg.get('username', 'Unknown user')
            text = msg.get('message_text', '')
            
            if text:
                context_lines.append(f"[{timestamp}] {username}: {text}")
        
        return "\n".join(context_lines) if context_lines else "No recent context available."
    
    def _build_conversation_string(self, messages: List[Dict]) -> str:
        """Build conversation string from message history."""
        if not messages:
            return "No messages to summarize."
        
        conversation_lines = []
        for msg in messages:
            timestamp = msg.get('timestamp', 'Unknown time')
            username = msg.get('username', 'Unknown user')
            text = msg.get('message_text', '')
            
            if text:
                conversation_lines.append(f"[{timestamp}] {username}: {text}")
        
        return "\n".join(conversation_lines) if conversation_lines else "No messages to summarize."
    
    def extract_username_from_mention(self, text: str) -> Optional[str]:
        """Extract username from @mention in text."""
        # Find @username pattern
        mentions = re.findall(r'@(\w+)', text)
        return mentions[0] if mentions else None
    
    def extract_key_value_from_text(self, text: str) -> Dict[str, str]:
        """Extract key-value pairs from natural language text."""
        # This is a simplified version - in production, you'd want more sophisticated parsing
        patterns = {
            'phone': r'(\d{3}[-.\s]?\d{3}[-.\s]?\d{4})',
            'email': r'([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,})',
            'url': r'(https?://[^\s]+)',
            'bank_account': r'(\d{6,20})',
        }
        
        extracted = {}
        for key, pattern in patterns.items():
            matches = re.findall(pattern, text)
            if matches:
                extracted[key] = matches[0]
        
        return extracted 