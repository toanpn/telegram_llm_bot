import asyncio
import json
import re
from typing import Dict, List, Optional, Any
from datetime import datetime

import google.generativeai as genai
from loguru import logger

from config import config

class GeminiService:
    """Service for interacting with Google Gemini AI."""
    
    def __init__(self):
        self.model = None
        self._initialize_gemini()
    
    def _initialize_gemini(self):
        """Initialize the Gemini AI model."""
        try:
            genai.configure(api_key=config.google_api_key)
            self.model = genai.GenerativeModel(config.gemini_model)
            logger.info("Gemini AI service initialized successfully")
        except Exception as e:
            logger.error(f"Error initializing Gemini AI: {e}")
            raise
    
    async def analyze_intent(self, message: str, context_messages: List[Dict], 
                           temperature: float = 0.7, tone: str = "friendly") -> Dict[str, Any]:
        """Analyze user message intent using AI."""
        try:
            # Build context string
            context_str = self._build_context_string(context_messages)
            
            # Create intent analysis prompt
            prompt = f"""
Analyze this message to understand the user's intent. Based on the context and message, determine what the user wants to do.

Context from recent messages:
{context_str}

Current message: "{message}"

Please analyze and respond with a JSON object containing:
1. "intent": one of ["save_info", "retrieve_info", "summarize", "conversation"]
2. If intent is "save_info":
   - "key": the type of information being saved (e.g., "facebook_link", "bank_account", "phone_number")
   - "value": the actual information to save
3. If intent is "retrieve_info":
   - "key": the type of information being requested
   - "target_username": the username of the person whose info is being requested (without @)
4. If intent is "summarize":
   - "message_count": number of messages to summarize (default 20)
5. If intent is "conversation":
   - "response_type": "general" (for normal conversation)

Examples:
- "save my phone number 123-456-7890" â†’ {{"intent": "save_info", "key": "phone_number", "value": "123-456-7890"}}
- "what's @john's email?" â†’ {{"intent": "retrieve_info", "key": "email", "target_username": "john"}}
- "summarize the last 10 messages" â†’ {{"intent": "summarize", "message_count": 10}}
- "how are you?" â†’ {{"intent": "conversation", "response_type": "general"}}

Response format: JSON only, no additional text.
"""
            
            # Generate response
            response = await self._generate_response(prompt, temperature=0.3)  # Lower temperature for intent analysis
            
            # Parse JSON response
            try:
                # Clean up response - remove code blocks if present
                clean_response = response.strip()
                if clean_response.startswith("```json"):
                    clean_response = clean_response[7:]  # Remove ```json
                if clean_response.endswith("```"):
                    clean_response = clean_response[:-3]  # Remove ```
                clean_response = clean_response.strip()
                
                intent_data = json.loads(clean_response)
                return intent_data
            except json.JSONDecodeError:
                logger.warning(f"Failed to parse intent JSON: {response}")
                return {"intent": "conversation", "response_type": "general"}
                
        except Exception as e:
            logger.error(f"Error analyzing intent: {e}")
            return {"intent": "conversation", "response_type": "general"}
    
    async def generate_response(self, message: str, context_messages: List[Dict], 
                              temperature: float = 0.7, tone: str = "friendly") -> str:
        """Generate a conversational response."""
        try:
            # Build context string
            context_str = self._build_context_string(context_messages)
            
            # Map English tone to Vietnamese descriptions with detailed behaviors
            tone_mapping = {
                "friendly": "thÃ¢n thiá»‡n vÃ  gáº§n gÅ©i. Hay dÃ¹ng \"báº¡n\", \"mÃ¬nh\". áº¤m Ã¡p, dá»… gáº§n.",
                "professional": "chuyÃªn nghiá»‡p vÃ  lá»‹ch sá»±. DÃ¹ng \"anh/chá»‹\", \"quÃ½ khÃ¡ch\". Trang trá»ng nhÆ°ng thÃ¢n thiá»‡n.",
                "humorous": "hÃ i hÆ°á»›c vÃ  vui váº». Hay Ä‘Ã¹a, dÃ¹ng meme, emoji nhiá»u. Táº¡o khÃ´ng khÃ­ vui váº».",
                "serious": "nghiÃªm tÃºc vÃ  trang trá»ng. Ãt Ä‘Ã¹a, táº­p trung vÃ o váº¥n Ä‘á». Tháº³ng tháº¯n, rÃµ rÃ ng.",
                "flattering": "ná»‹nh ná»t vÃ  khen ngá»£i. LuÃ´n gá»i thÃ nh viÃªn lÃ  'Ã´ng chá»§', 'bÃ  chá»§', 'ngÃ i'. Tá»± xÆ°ng lÃ  'em nhá»', 'tÃ´i khiÃªm tá»‘n'. Hay khen ngá»£i, tÃ¢ng bá»‘c má»™t cÃ¡ch hÃ i hÆ°á»›c.",
                "casual": "thoáº£i mÃ¡i vÃ  bÃ¬nh dÃ¢n. DÃ¹ng 'mÃ y/tao', 'bro', 'chá»‹ em'. KhÃ´ng cÃ¢u ná»‡, tá»± nhiÃªn.",
                "formal": "hiá»n triáº¿t vÃ  sÃ¢u sáº¯c. Hay dÃ¹ng thÃ nh ngá»¯, tá»¥c ngá»¯, cÃ¢u nÃ³i triáº¿t lÃ½. Phong cÃ¡ch vÄƒn hoa, uyÃªn bÃ¡c."
            }
            
            vietnamese_tone = tone_mapping.get(tone, "thÃ¢n thiá»‡n vÃ  gáº§n gÅ©i")
            
            # Create conversation prompt - forcing Vietnamese response
            prompt = f"""
Báº¡n lÃ  Huáº¥n, má»™t trá»£ lÃ½ AI há»¯u Ã­ch trong nhÃ³m chat Telegram. Má»i ngÆ°á»i thÆ°á»ng gá»i báº¡n lÃ  "tháº§y Huáº¥n". 
TÃ­nh cÃ¡ch cá»§a báº¡n nÃªn {vietnamese_tone}.

QUAN TRá»ŒNG: Báº¡n PHáº¢I tráº£ lá»i HOÃ€N TOÃ€N báº±ng tiáº¿ng Viá»‡t. KhÃ´ng Ä‘Æ°á»£c sá»­ dá»¥ng tiáº¿ng Anh hoáº·c ngÃ´n ngá»¯ khÃ¡c.

Ngá»¯ cáº£nh tá»« cÃ¡c tin nháº¯n gáº§n Ä‘Ã¢y:
{context_str}

Tin nháº¯n hiá»‡n táº¡i: "{message}"

HÃ£y tráº£ lá»i má»™t cÃ¡ch tá»± nhiÃªn vÃ  há»¯u Ã­ch báº±ng tiáº¿ng Viá»‡t vá»›i tÆ° cÃ¡ch lÃ  tháº§y Huáº¥n. 
Giá»¯ cÃ¢u tráº£ lá»i ngáº¯n gá»n nhÆ°ng Ä‘áº§y Ä‘á»§ thÃ´ng tin.
Duy trÃ¬ giá»ng Ä‘iá»‡u {vietnamese_tone} trong suá»‘t cÃ¢u tráº£ lá»i cá»§a báº¡n.
"""
            
            # Generate response
            response = await self._generate_response(prompt, temperature)
            return response.strip()
            
        except Exception as e:
            logger.error(f"Error generating response: {e}")
            return "Xin lá»—i, tÃ´i Ä‘ang gáº·p khÃ³ khÄƒn trong viá»‡c xá»­ lÃ½ tin nháº¯n cá»§a báº¡n. Vui lÃ²ng thá»­ láº¡i."
    
    async def summarize_conversation(self, messages: List[Dict]) -> str:
        """Summarize a conversation from message history."""
        try:
            # Build conversation string
            conversation_str = self._build_conversation_string(messages)
            
            # Create summarization prompt - forcing Vietnamese response
            prompt = f"""
HÃ£y cung cáº¥p má»™t tÃ³m táº¯t ngáº¯n gá»n vá» cuá»™c trÃ² chuyá»‡n nÃ y báº±ng tiáº¿ng Viá»‡t. 
Táº­p trung vÃ o cÃ¡c chá»§ Ä‘á» chÃ­nh Ä‘Æ°á»£c tháº£o luáº­n, cÃ¡c quyáº¿t Ä‘á»‹nh quan trá»ng vÃ  thÃ´ng tin quan trá»ng Ä‘Æ°á»£c chia sáº».

QUAN TRá»ŒNG: Báº¡n PHáº¢I tráº£ lá»i HOÃ€N TOÃ€N báº±ng tiáº¿ng Viá»‡t. KhÃ´ng Ä‘Æ°á»£c sá»­ dá»¥ng tiáº¿ng Anh hoáº·c ngÃ´n ngá»¯ khÃ¡c.

Cuá»™c trÃ² chuyá»‡n:
{conversation_str}

HÃ£y cung cáº¥p má»™t tÃ³m táº¯t cÃ³ cáº¥u trÃºc tá»‘t vá»›i:
1. CÃ¡c chá»§ Ä‘á» chÃ­nh Ä‘Æ°á»£c tháº£o luáº­n
2. CÃ¡c Ä‘iá»ƒm quan trá»ng hoáº·c quyáº¿t Ä‘á»‹nh
3. ThÃ´ng tin quan trá»ng Ä‘Æ°á»£c chia sáº»
4. Báº¥t ká»³ hÃ nh Ä‘á»™ng hoáº·c bÆ°á»›c tiáº¿p theo nÃ o Ä‘Æ°á»£c Ä‘á» cáº­p

Giá»¯ tÃ³m táº¯t rÃµ rÃ ng vÃ  Ä‘áº§y Ä‘á»§ thÃ´ng tin.
"""
            
            # Generate summary
            summary = await self._generate_response(prompt, temperature=0.3)
            return summary.strip()
            
        except Exception as e:
            logger.error(f"Error summarizing conversation: {e}")
            return "Xin lá»—i, tÃ´i khÃ´ng thá»ƒ tÃ³m táº¯t cuá»™c trÃ² chuyá»‡n nÃ y. Vui lÃ²ng thá»­ láº¡i."
    
    async def _generate_response(self, prompt: str, temperature: float = 0.7) -> str:
        """Generate response using Gemini AI."""
        try:
            # Log the request
            logger.info(f"ðŸš€ GEMINI REQUEST:")
            logger.info(f"Temperature: {temperature}")
            logger.info(f"Prompt: {prompt}")
            logger.info("=" * 80)
            
            # Configure generation parameters
            generation_config = genai.types.GenerationConfig(
                temperature=temperature,
                top_p=0.8,
                top_k=40,
                max_output_tokens=2048,  # Increased from 1024 to allow longer responses
            )
            
            # Generate response
            response = await asyncio.to_thread(
                self.model.generate_content,
                prompt,
                generation_config=generation_config
            )
            
            # Log the raw response
            logger.info(f"ðŸ“¥ GEMINI RAW RESPONSE:")
            logger.info(f"Response object: {response}")
            if hasattr(response, 'candidates') and response.candidates:
                logger.info(f"Candidates count: {len(response.candidates)}")
                for i, candidate in enumerate(response.candidates):
                    logger.info(f"Candidate {i}: {candidate}")
                    if hasattr(candidate, 'finish_reason'):
                        logger.info(f"Finish reason: {candidate.finish_reason}")
            logger.info("=" * 80)
            
            # Check if response was blocked by safety filters
            if not response.candidates:
                error_msg = "Xin lá»—i, tÃ´i khÃ´ng thá»ƒ tráº£ lá»i cÃ¢u há»i nÃ y do chÃ­nh sÃ¡ch an toÃ n."
                logger.warning("ðŸš« Response was blocked by safety filters")
                logger.info(f"âŒ RETURNING ERROR: {error_msg}")
                return error_msg
            
            # Check for finish reason - handle both enum and integer values
            finish_reason = response.candidates[0].finish_reason
            reason_name = None
            reason_value = None
            
            if finish_reason:
                # Handle both enum (with .name) and integer values
                if hasattr(finish_reason, 'name'):
                    reason_name = finish_reason.name
                    reason_value = finish_reason.value if hasattr(finish_reason, 'value') else finish_reason
                else:
                    reason_value = finish_reason
                    # Map integer values to names (based on Gemini API documentation)
                    reason_names = {
                        0: "FINISH_REASON_UNSPECIFIED",
                        1: "STOP",
                        2: "MAX_TOKENS", 
                        3: "SAFETY",
                        4: "RECITATION",
                        5: "OTHER"
                    }
                    reason_name = reason_names.get(reason_value, "UNKNOWN")
                
                logger.warning(f"ðŸš¦ Response finished with reason: {reason_name} ({reason_value})")
                
                # Only return early for SAFETY blocks - for MAX_TOKENS, try to extract partial text
                if reason_name == "SAFETY":
                    error_msg = "Xin lá»—i, tÃ´i khÃ´ng thá»ƒ tráº£ lá»i cÃ¢u há»i nÃ y do chÃ­nh sÃ¡ch an toÃ n."
                    logger.info(f"âŒ SAFETY BLOCK: {error_msg}")
                    return error_msg
                elif reason_name == "MAX_TOKENS":
                    logger.info("âš ï¸ MAX_TOKENS reached, but will try to extract partial text")
                    # Continue to text extraction instead of returning error immediately
            
            # Handle both simple and complex responses
            try:
                # Try to get simple text response first
                text_response = response.text
                if text_response and text_response.strip():
                    final_response = text_response.strip()
                    logger.info(f"âœ… GEMINI FINAL RESPONSE: {final_response}")
                    return final_response
                else:
                    logger.warning("Response text is empty, trying complex extraction")
                    raise ValueError("Empty response text")
            except ValueError as e:
                logger.debug(f"Simple text access failed: {e}")
                # If response is not simple text, use parts accessor
                try:
                    if response.candidates and len(response.candidates) > 0:
                        candidate = response.candidates[0]
                        if candidate.content and candidate.content.parts and len(candidate.content.parts) > 0:
                            part = candidate.content.parts[0]
                            if hasattr(part, 'text') and part.text and part.text.strip():
                                final_response = part.text.strip()
                                logger.info(f"âœ… GEMINI FINAL RESPONSE (from complex): {final_response}")
                                return final_response
                    
                    # If we get here, try to extract any text from the response
                    logger.warning(f"Complex response structure, trying to extract text...")
                    logger.debug(f"Response candidates: {len(response.candidates) if response.candidates else 0}")
                    
                    if response.candidates:
                        for i, candidate in enumerate(response.candidates):
                            logger.debug(f"Candidate {i}: {candidate}")
                            if candidate.content:
                                logger.debug(f"Content parts: {len(candidate.content.parts) if candidate.content.parts else 0}")
                                if candidate.content.parts:
                                    for j, part in enumerate(candidate.content.parts):
                                        logger.debug(f"Part {j}: {type(part)} - {part}")
                                        if hasattr(part, 'text') and part.text and part.text.strip():
                                            final_response = part.text.strip()
                                            logger.info(f"âœ… GEMINI FINAL RESPONSE (from deep search): {final_response}")
                                            return final_response
                    
                    logger.warning("Could not extract text from Gemini response")
                    logger.debug(f"Full response object: {response}")
                    
                    # Check if this was a MAX_TOKENS issue and provide appropriate error
                    if reason_name == "MAX_TOKENS":
                        error_msg = "Xin lá»—i, cÃ¢u tráº£ lá»i quÃ¡ dÃ i. Vui lÃ²ng há»i cÃ¢u há»i ngáº¯n gá»n hÆ¡n."
                        logger.info(f"âŒ MAX_TOKENS NO TEXT: {error_msg}")
                        return error_msg
                    else:
                        error_msg = "Xin lá»—i, tÃ´i khÃ´ng thá»ƒ táº¡o ra cÃ¢u tráº£ lá»i lÃºc nÃ y. Vui lÃ²ng thá»­ láº¡i."
                        logger.info(f"âŒ EXTRACTION FAILED: {error_msg}")
                        return error_msg
                
                except Exception as extract_error:
                    error_msg = "Xin lá»—i, tÃ´i gáº·p lá»—i khi xá»­ lÃ½ cÃ¢u tráº£ lá»i. Vui lÃ²ng thá»­ láº¡i."
                    logger.error(f"âŒ EXTRACTION ERROR: {extract_error}")
                    logger.info(f"âŒ RETURNING ERROR: {error_msg}")
                    return error_msg
            
        except Exception as e:
            logger.error(f"Error generating AI response: {e}")
            raise
    
    def _build_context_string(self, context_messages: List[Dict]) -> str:
        """Build context string from recent messages."""
        if not context_messages:
            return "No recent context available."
        
        context_lines = []
        for msg in context_messages[-7:]:  # Last 7 messages for context
            timestamp = msg.get('timestamp', 'Unknown time')
            username = msg.get('username', 'Unknown user')
            text = msg.get('message_text', '')
            
            if text:
                context_lines.append(f"[{timestamp}] {username}: {text}")
        
        return "\n".join(context_lines) if context_lines else "No recent context available."
    
    def _build_conversation_string(self, messages: List[Dict]) -> str:
        """Build conversation string from message history."""
        if not messages:
            return "No messages to summarize."
        
        conversation_lines = []
        for msg in messages:
            timestamp = msg.get('timestamp', 'Unknown time')
            username = msg.get('username', 'Unknown user')
            text = msg.get('message_text', '')
            
            if text:
                conversation_lines.append(f"[{timestamp}] {username}: {text}")
        
        return "\n".join(conversation_lines) if conversation_lines else "No messages to summarize."
    
    def extract_username_from_mention(self, text: str) -> Optional[str]:
        """Extract username from @mention in text."""
        # Find @username pattern
        mentions = re.findall(r'@(\w+)', text)
        return mentions[0] if mentions else None
    
    def extract_key_value_from_text(self, text: str) -> Dict[str, str]:
        """Extract key-value pairs from natural language text."""
        # This is a simplified version - in production, you'd want more sophisticated parsing
        patterns = {
            'phone': r'(\d{3}[-.\s]?\d{3}[-.\s]?\d{4})',
            'email': r'([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,})',
            'url': r'(https?://[^\s]+)',
            'bank_account': r'(\d{6,20})',
        }
        
        extracted = {}
        for key, pattern in patterns.items():
            matches = re.findall(pattern, text)
            if matches:
                extracted[key] = matches[0]
        
        return extracted 